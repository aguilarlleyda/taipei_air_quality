{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series forecasting of Taipei's air quality index - dataset preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What follows are the preprocessing steps taken to obtain `df_ai`, the dataset used in the main notebook of this project. This dataset is built from those datasets on the [website of the Ministry of Environment of Taiwan](https://data.moenv.gov.tw/en/dataset/detail/AQX_P_488). Each of those datasets contain information for a single month on hourly Air Quality Index (AQI) values for multiple measuring sites of different Taiwanese cities and regions. By following the procedure that can be reproduced with this notebook's code, those datasets were combined and processed into a single dataset with the hourly information only for Taipei city, with each hourly value reflecting the average across the different measuring sites of the city. Some missing information is interpolated.\n",
    "\n",
    "While extensive markdown explanation is absent, the comments within the code chunks should be enough to understand each step of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries for math, data wrangling and file reading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and concatenate yearly air quality datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z4/rsx400qn1jldyy0yky98y40h0000gn/T/ipykernel_1117/1442458380.py:2: DtypeWarning: Columns (9,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_aqi = pd.concat([pd.read_csv(f'monthly_datasets/{f}') for f in os.listdir('monthly_datasets') if f.endswith('.csv')])\n",
      "/var/folders/z4/rsx400qn1jldyy0yky98y40h0000gn/T/ipykernel_1117/1442458380.py:2: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_aqi = pd.concat([pd.read_csv(f'monthly_datasets/{f}') for f in os.listdir('monthly_datasets') if f.endswith('.csv')])\n",
      "/var/folders/z4/rsx400qn1jldyy0yky98y40h0000gn/T/ipykernel_1117/1442458380.py:2: DtypeWarning: Columns (5,6,7,8,9,10,11,13,18,19,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_aqi = pd.concat([pd.read_csv(f'monthly_datasets/{f}') for f in os.listdir('monthly_datasets') if f.endswith('.csv')])\n",
      "/var/folders/z4/rsx400qn1jldyy0yky98y40h0000gn/T/ipykernel_1117/1442458380.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_aqi = pd.concat([pd.read_csv(f'monthly_datasets/{f}') for f in os.listdir('monthly_datasets') if f.endswith('.csv')])\n",
      "/var/folders/z4/rsx400qn1jldyy0yky98y40h0000gn/T/ipykernel_1117/1442458380.py:2: DtypeWarning: Columns (5,7,8,9,10,11,12,13,19,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_aqi = pd.concat([pd.read_csv(f'monthly_datasets/{f}') for f in os.listdir('monthly_datasets') if f.endswith('.csv')])\n",
      "/var/folders/z4/rsx400qn1jldyy0yky98y40h0000gn/T/ipykernel_1117/1442458380.py:2: DtypeWarning: Columns (5,10,11,12,13,19,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_aqi = pd.concat([pd.read_csv(f'monthly_datasets/{f}') for f in os.listdir('monthly_datasets') if f.endswith('.csv')])\n"
     ]
    }
   ],
   "source": [
    "#read and concatenate individual datasets within the monthly_datasets folder\n",
    "df_aqi = pd.concat([pd.read_csv(f'monthly_datasets/{f}') for f in os.listdir('monthly_datasets') if f.endswith('.csv')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datacreationdate</th>\n",
       "      <th>county</th>\n",
       "      <th>sitename</th>\n",
       "      <th>aqi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-01 00:00</td>\n",
       "      <td>高雄市</td>\n",
       "      <td>鳳山</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-01 00:00</td>\n",
       "      <td>高雄市</td>\n",
       "      <td>大寮</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-01 00:00</td>\n",
       "      <td>高雄市</td>\n",
       "      <td>林園</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-01 00:00</td>\n",
       "      <td>高雄市</td>\n",
       "      <td>楠梓</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-01 00:00</td>\n",
       "      <td>高雄市</td>\n",
       "      <td>左營</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61915</th>\n",
       "      <td>2022-09-30 23:00</td>\n",
       "      <td>南投縣</td>\n",
       "      <td>南投</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61916</th>\n",
       "      <td>2022-09-30 23:00</td>\n",
       "      <td>雲林縣</td>\n",
       "      <td>斗六</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61917</th>\n",
       "      <td>2022-09-30 23:00</td>\n",
       "      <td>雲林縣</td>\n",
       "      <td>崙背</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61918</th>\n",
       "      <td>2022-09-30 23:00</td>\n",
       "      <td>新北市</td>\n",
       "      <td>新北(樹林)</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61919</th>\n",
       "      <td>2022-09-30 23:00</td>\n",
       "      <td>屏東縣</td>\n",
       "      <td>屏東(枋寮)</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5929486 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       datacreationdate county sitename   aqi\n",
       "0      2019-08-01 00:00    高雄市       鳳山  22.0\n",
       "1      2019-08-01 00:00    高雄市       大寮  43.0\n",
       "2      2019-08-01 00:00    高雄市       林園  27.0\n",
       "3      2019-08-01 00:00    高雄市       楠梓  47.0\n",
       "4      2019-08-01 00:00    高雄市       左營  28.0\n",
       "...                 ...    ...      ...   ...\n",
       "61915  2022-09-30 23:00    南投縣       南投  72.0\n",
       "61916  2022-09-30 23:00    雲林縣       斗六  72.0\n",
       "61917  2022-09-30 23:00    雲林縣       崙背  55.0\n",
       "61918  2022-09-30 23:00    新北市   新北(樹林)  48.0\n",
       "61919  2022-09-30 23:00    屏東縣   屏東(枋寮)  44.0\n",
       "\n",
       "[5929486 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#keep only relevant columns\n",
    "df_aqi = df_aqi[['datacreationdate','county','sitename','aqi']]\n",
    "\n",
    "#display the DataFrame with the relevant columns\n",
    "display(df_aqi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Taipei City information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['高雄市', '屏東縣', '臺東縣', '雲林縣', '南投縣', '彰化縣', '臺中市', '苗栗縣', '新竹市',\n",
       "       '新竹縣', '桃園市', '臺北市', '新北市', '嘉義縣', '嘉義市', '臺南市', '澎湖縣', '金門縣',\n",
       "       '連江縣', '基隆市', '宜蘭縣', '花蓮縣', 'New Taipei City', 'Taipei City',\n",
       "       'Taoyuan County', 'Hsinchu County', 'Hsinchu City',\n",
       "       'Miaoli County', 'Taichung City', 'Changhua County',\n",
       "       'Nantou County', 'Yunlin County', 'Chiayi County', 'Chiayi City',\n",
       "       'Tainan City', 'Kaohsiung City', 'Pingtung County',\n",
       "       'Taitung County', 'Hualien County', 'Yilan County', 'Keelung City',\n",
       "       'Lienchiang County', 'Kinmen County', 'Penghu County', nan],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#identify unique county names\n",
    "unique_counties = df_aqi['county'].unique()\n",
    "\n",
    "#display unique county names\n",
    "display(unique_counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(507371, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create list with Taipei City name in Chinese and English and keep only those rows where county equals to one of those names\n",
    "taipei_city_names = ['臺北市','Taipei City']\n",
    "df_aqi = df_aqi[df_aqi.county.isin(taipei_city_names)]\n",
    "\n",
    "#display length of DataFrame and make sure it is smaller than the original\n",
    "display(df_aqi.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unify site names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['大同', '松山', '古亭', '萬華', '中山', '士林', '陽明', 'Shilin', 'Zhongshan',\n",
       "       'Wanhua', 'Guting', 'Songshan', 'Datong', 'Yangming', '行動監測03'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#identify unique site names, where each site name refers to a measuring site from which AQI readings were obtained\n",
    "unique_sitenames = df_aqi['sitename'].unique()\n",
    "\n",
    "#display unique site names\n",
    "display(unique_sitenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Datong', 'Songshan', 'Guting', 'Wanhua', 'Zhongshan', 'Shilin',\n",
       "       'Yangming', 'Mobile Monitoring 03'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create a dictionary mapping Chinese to English site names\n",
    "site_name_mapping = {\n",
    "    '大同': 'Datong',\n",
    "    '松山': 'Songshan',\n",
    "    '古亭': 'Guting',\n",
    "    '萬華': 'Wanhua',\n",
    "    '中山': 'Zhongshan',\n",
    "    '士林': 'Shilin',\n",
    "    '陽明': 'Yangming',\n",
    "    '行動監測03': 'Mobile Monitoring 03'\n",
    "}\n",
    "\n",
    "#define function to unify site names into English\n",
    "def unify_site_name(site_name):\n",
    "    return site_name_mapping.get(site_name, site_name)\n",
    "\n",
    "#apply the function to the sitename column\n",
    "df_aqi['sitename'] = df_aqi['sitename'].apply(unify_site_name)\n",
    "\n",
    "#get and display unique sitenames after unifying them, making sure no English-Chinese duplicity is present anymore\n",
    "unique_sitenames = df_aqi['sitename'].unique()\n",
    "display(unique_sitenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of county column, as all rows now correspond to the Taipei City county\n",
    "df_aqi = df_aqi[['datacreationdate','sitename','aqi']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datacreationdate</th>\n",
       "      <th>sitename</th>\n",
       "      <th>aqi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37969</th>\n",
       "      <td>2018-01-21 18:00</td>\n",
       "      <td>Songshan</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37982</th>\n",
       "      <td>2018-01-21 18:00</td>\n",
       "      <td>Songshan</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37975</th>\n",
       "      <td>2018-01-21 18:00</td>\n",
       "      <td>Datong</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37983</th>\n",
       "      <td>2018-01-21 18:00</td>\n",
       "      <td>Datong</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21138</th>\n",
       "      <td>2020-11-11 17:00</td>\n",
       "      <td>Zhongshan</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97873</th>\n",
       "      <td>2023-12-24 23:00</td>\n",
       "      <td>Shilin</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97756</th>\n",
       "      <td>2023-12-24 23:00</td>\n",
       "      <td>Guting</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97870</th>\n",
       "      <td>2023-12-24 23:00</td>\n",
       "      <td>Guting</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97754</th>\n",
       "      <td>2023-12-24 23:00</td>\n",
       "      <td>Datong</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97868</th>\n",
       "      <td>2023-12-24 23:00</td>\n",
       "      <td>Datong</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88488 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       datacreationdate   sitename   aqi\n",
       "37969  2018-01-21 18:00   Songshan  43.0\n",
       "37982  2018-01-21 18:00   Songshan  43.0\n",
       "37975  2018-01-21 18:00     Datong  35.0\n",
       "37983  2018-01-21 18:00     Datong  35.0\n",
       "21138  2020-11-11 17:00  Zhongshan  39.0\n",
       "...                 ...        ...   ...\n",
       "97873  2023-12-24 23:00     Shilin  48.0\n",
       "97756  2023-12-24 23:00     Guting  52.0\n",
       "97870  2023-12-24 23:00     Guting  52.0\n",
       "97754  2023-12-24 23:00     Datong  60.0\n",
       "97868  2023-12-24 23:00     Datong  60.0\n",
       "\n",
       "[88488 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get those rows that share the same datacreationdate and sitename values\n",
    "duplicate_rows = df_aqi[df_aqi.duplicated(subset=['datacreationdate', 'sitename'], keep=False)]\n",
    "\n",
    "#display sorted duplicate rows\n",
    "duplicate_rows.sort_values(['datacreationdate', 'sitename'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datacreationdate</th>\n",
       "      <th>sitename</th>\n",
       "      <th>aqi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34373</th>\n",
       "      <td>2020-11-20 01:00</td>\n",
       "      <td>Zhongshan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34464</th>\n",
       "      <td>2020-11-20 01:00</td>\n",
       "      <td>Zhongshan</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44533</th>\n",
       "      <td>2020-11-22 13:00</td>\n",
       "      <td>Wanhua</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44618</th>\n",
       "      <td>2020-11-22 13:00</td>\n",
       "      <td>Wanhua</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45214</th>\n",
       "      <td>2020-11-22 17:00</td>\n",
       "      <td>Datong</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118868</th>\n",
       "      <td>2021-06-30 23:00</td>\n",
       "      <td>Wanhua</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8831</th>\n",
       "      <td>2022-03-03 10:00</td>\n",
       "      <td>Songshan</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8947</th>\n",
       "      <td>2022-03-03 10:00</td>\n",
       "      <td>Songshan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9013</th>\n",
       "      <td>2022-03-03 11:00</td>\n",
       "      <td>Songshan</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9073</th>\n",
       "      <td>2022-03-03 11:00</td>\n",
       "      <td>Songshan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18676 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        datacreationdate   sitename    aqi\n",
       "34373   2020-11-20 01:00  Zhongshan    NaN\n",
       "34464   2020-11-20 01:00  Zhongshan   52.0\n",
       "44533   2020-11-22 13:00     Wanhua   32.0\n",
       "44618   2020-11-22 13:00     Wanhua   33.0\n",
       "45214   2020-11-22 17:00     Datong    NaN\n",
       "...                  ...        ...    ...\n",
       "118868  2021-06-30 23:00     Wanhua   40.0\n",
       "8831    2022-03-03 10:00   Songshan  103.0\n",
       "8947    2022-03-03 10:00   Songshan    NaN\n",
       "9013    2022-03-03 11:00   Songshan  103.0\n",
       "9073    2022-03-03 11:00   Songshan    NaN\n",
       "\n",
       "[18676 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove exact duplicates while keeping only the first occurrence\n",
    "df_aqi = df_aqi.drop_duplicates(keep='first')\n",
    "\n",
    "#to identify partial duplicates that may remain, get those rows that share the same datacreationdate and sitename values and display them sorted\n",
    "duplicate_rows = df_aqi[df_aqi.duplicated(subset=['datacreationdate', 'sitename'], keep=False)]\n",
    "duplicate_rows.sort_values(['datacreationdate', 'sitename'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datacreationdate</th>\n",
       "      <th>sitename</th>\n",
       "      <th>aqi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44533</th>\n",
       "      <td>2020-11-22 13:00</td>\n",
       "      <td>Wanhua</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44618</th>\n",
       "      <td>2020-11-22 13:00</td>\n",
       "      <td>Wanhua</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50174</th>\n",
       "      <td>2020-11-23 22:00</td>\n",
       "      <td>Datong</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50198</th>\n",
       "      <td>2020-11-23 22:00</td>\n",
       "      <td>Datong</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59358</th>\n",
       "      <td>2020-11-26 04:00</td>\n",
       "      <td>Zhongshan</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118456</th>\n",
       "      <td>2021-06-30 21:00</td>\n",
       "      <td>Guting</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118540</th>\n",
       "      <td>2021-06-30 22:00</td>\n",
       "      <td>Yangming</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118688</th>\n",
       "      <td>2021-06-30 22:00</td>\n",
       "      <td>Yangming</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118750</th>\n",
       "      <td>2021-06-30 23:00</td>\n",
       "      <td>Wanhua</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118868</th>\n",
       "      <td>2021-06-30 23:00</td>\n",
       "      <td>Wanhua</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18286 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        datacreationdate   sitename   aqi\n",
       "44533   2020-11-22 13:00     Wanhua  32.0\n",
       "44618   2020-11-22 13:00     Wanhua  33.0\n",
       "50174   2020-11-23 22:00     Datong  57.0\n",
       "50198   2020-11-23 22:00     Datong  54.0\n",
       "59358   2020-11-26 04:00  Zhongshan  32.0\n",
       "...                  ...        ...   ...\n",
       "118456  2021-06-30 21:00     Guting  41.0\n",
       "118540  2021-06-30 22:00   Yangming  31.0\n",
       "118688  2021-06-30 22:00   Yangming  30.0\n",
       "118750  2021-06-30 23:00     Wanhua  39.0\n",
       "118868  2021-06-30 23:00     Wanhua  40.0\n",
       "\n",
       "[18286 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove those partial duplicate rows with NaN in the aqi column\n",
    "df_aqi = df_aqi[df_aqi['aqi'].notna()]\n",
    "\n",
    "#get those rows that share the same datacreationdate and sitename values and display them sorted\n",
    "duplicate_rows = df_aqi[df_aqi.duplicated(subset=['datacreationdate', 'sitename'], keep=False)]\n",
    "duplicate_rows.sort_values(['datacreationdate', 'sitename'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datacreationdate  sitename \n",
       "2020-11-22 13:00  Wanhua       2\n",
       "2020-11-23 22:00  Datong       2\n",
       "2020-11-26 04:00  Zhongshan    2\n",
       "2020-11-30 17:00  Guting       2\n",
       "2020-12-02 05:00  Wanhua       2\n",
       "                              ..\n",
       "2021-06-30 19:00  Guting       2\n",
       "2021-06-30 21:00  Guting       2\n",
       "                  Songshan     2\n",
       "2021-06-30 22:00  Yangming     2\n",
       "2021-06-30 23:00  Wanhua       2\n",
       "Name: aqi, Length: 9143, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check how many aqi unique values we have within each group of rows with the same datacreationdate and sitename\n",
    "duplicate_rows_grouped = duplicate_rows.groupby(['datacreationdate', 'sitename'])['aqi'].nunique()\n",
    "\n",
    "#get and display the groups where there are different 'aqi' values\n",
    "groups_with_different_aqi = duplicate_rows_grouped[duplicate_rows_grouped > 1]\n",
    "display(groups_with_different_aqi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datacreationdate</th>\n",
       "      <th>sitename</th>\n",
       "      <th>aqi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [datacreationdate, sitename, aqi]\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get indices of aforementioned groups and use them to filter the original duplicate rows to get only those with different 'aqi' values\n",
    "groups_with_different_aqi_indices = duplicate_rows_grouped[duplicate_rows_grouped > 1].index\n",
    "duplicates_with_different_aqi = duplicate_rows.set_index(['datacreationdate', 'sitename']).loc[groups_with_different_aqi_indices].reset_index()\n",
    "\n",
    "#to solve divergence in the values, calculate the average 'aqi' for each group and round to the nearest integer\n",
    "duplicates_averaged_aqi = duplicates_with_different_aqi.groupby(['datacreationdate', 'sitename'])['aqi'].mean().apply(np.ceil).astype(int).reset_index()\n",
    "\n",
    "#remove the original duplicate rows with different aqi by creating a boolean mask and applying it\n",
    "mask = df_aqi.set_index(['datacreationdate', 'sitename']).index.isin(duplicates_with_different_aqi.set_index(['datacreationdate', 'sitename']).index)\n",
    "df_aqi = df_aqi[~mask] #apply the mask\n",
    "\n",
    "#add the averaged rows back to the cleaned DataFrame\n",
    "df_aqi = pd.concat([df_aqi, duplicates_averaged_aqi], ignore_index=True)\n",
    "\n",
    "#get those rows that share the same datacreationdate and sitename values and display them sorted, expecting an empty DataFrame that will mean that no duplicates exist anymore\n",
    "duplicate_rows = df_aqi[df_aqi.duplicated(subset=['datacreationdate', 'sitename'], keep=False)]\n",
    "duplicate_rows.sort_values(['datacreationdate', 'sitename'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if all values within each column conform to right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datacreationdate</th>\n",
       "      <th>sitename</th>\n",
       "      <th>aqi</th>\n",
       "      <th>datacreationdate2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27381</th>\n",
       "      <td>2023/11/13 10:00:00</td>\n",
       "      <td>Guting</td>\n",
       "      <td>51.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27382</th>\n",
       "      <td>2023/11/13 10:00:00</td>\n",
       "      <td>Wanhua</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27383</th>\n",
       "      <td>2023/11/13 10:00:00</td>\n",
       "      <td>Zhongshan</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27384</th>\n",
       "      <td>2023/11/13 10:00:00</td>\n",
       "      <td>Yangming</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27385</th>\n",
       "      <td>2023/11/13 10:00:00</td>\n",
       "      <td>Shilin</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27386</th>\n",
       "      <td>2023/11/13 10:00:00</td>\n",
       "      <td>Songshan</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27387</th>\n",
       "      <td>2023/11/13 10:00:00</td>\n",
       "      <td>Datong</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          datacreationdate   sitename   aqi datacreationdate2\n",
       "27381  2023/11/13 10:00:00     Guting  51.0               NaT\n",
       "27382  2023/11/13 10:00:00     Wanhua  44.0               NaT\n",
       "27383  2023/11/13 10:00:00  Zhongshan  40.0               NaT\n",
       "27384  2023/11/13 10:00:00   Yangming  31.0               NaT\n",
       "27385  2023/11/13 10:00:00     Shilin  35.0               NaT\n",
       "27386  2023/11/13 10:00:00   Songshan  60.0               NaT\n",
       "27387  2023/11/13 10:00:00     Datong  44.0               NaT"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create DataFrame where we convert datacreationdate to datetime, coercing errors to NaT\n",
    "df_aqi_formatcheck = df_aqi.copy()\n",
    "df_aqi_formatcheck['datacreationdate2'] = pd.to_datetime(df_aqi_formatcheck['datacreationdate'], errors='coerce')\n",
    "\n",
    "#display rows with NaT values in datacreationdate\n",
    "wrong_format_dates = df_aqi_formatcheck[df_aqi_formatcheck['datacreationdate2'].isna()]\n",
    "display(wrong_format_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datacreationdate</th>\n",
       "      <th>sitename</th>\n",
       "      <th>aqi</th>\n",
       "      <th>datacreationdate2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [datacreationdate, sitename, aqi, datacreationdate2]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#since the different format is separation with '/' instead of ':', replace rows with wrong format by rows with good format\n",
    "df_aqi.loc[df_aqi['datacreationdate'] == '2023/11/13 10:00:00', 'datacreationdate'] = '2020-11-22 13:00'\n",
    "\n",
    "#repeat former steps again to check if bad format rows remain, where an empty DataFrame would mean no rows with bad format\n",
    "df_aqi_formatcheck = df_aqi.copy()\n",
    "df_aqi_formatcheck['datacreationdate2'] = pd.to_datetime(df_aqi_formatcheck['datacreationdate'], errors='coerce')\n",
    "wrong_format_dates = df_aqi_formatcheck[df_aqi_formatcheck['datacreationdate2'].isna()]\n",
    "display(wrong_format_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate average air quality index across all sites for each time stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datacreationdate</th>\n",
       "      <th>aqi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-11-25 13:00</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-11-25 14:00</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-11-25 15:00</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-11-25 16:00</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-11-25 17:00</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66102</th>\n",
       "      <td>2024-06-30 19:00</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66103</th>\n",
       "      <td>2024-06-30 20:00</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66104</th>\n",
       "      <td>2024-06-30 21:00</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66105</th>\n",
       "      <td>2024-06-30 22:00</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66106</th>\n",
       "      <td>2024-06-30 23:00</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66107 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       datacreationdate  aqi\n",
       "0      2016-11-25 13:00   27\n",
       "1      2016-11-25 14:00   27\n",
       "2      2016-11-25 15:00   27\n",
       "3      2016-11-25 16:00   28\n",
       "4      2016-11-25 17:00   28\n",
       "...                 ...  ...\n",
       "66102  2024-06-30 19:00   34\n",
       "66103  2024-06-30 20:00   33\n",
       "66104  2024-06-30 21:00   33\n",
       "66105  2024-06-30 22:00   32\n",
       "66106  2024-06-30 23:00   33\n",
       "\n",
       "[66107 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#group by 'datacreationdate' and calculate the average 'aqi' across all 'sitename'\n",
    "df_aqi = df_aqi.groupby('datacreationdate')['aqi'].mean().round().astype(int).reset_index()\n",
    "\n",
    "#display final DataFrame\n",
    "display(df_aqi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for missing hourly data and create it through interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing timestamps:\n",
      "DatetimeIndex(['2016-11-28 19:00:00', '2016-11-28 20:00:00',\n",
      "               '2016-11-28 21:00:00', '2016-11-28 22:00:00',\n",
      "               '2016-11-28 23:00:00', '2016-11-29 00:00:00',\n",
      "               '2016-11-29 01:00:00', '2016-11-29 02:00:00',\n",
      "               '2016-11-29 03:00:00', '2016-11-29 04:00:00',\n",
      "               ...\n",
      "               '2024-01-07 09:00:00', '2024-02-18 14:00:00',\n",
      "               '2024-05-13 05:00:00', '2024-05-13 10:00:00',\n",
      "               '2024-06-24 05:00:00', '2024-06-24 06:00:00',\n",
      "               '2024-06-24 07:00:00', '2024-06-24 08:00:00',\n",
      "               '2024-06-24 09:00:00', '2024-06-24 10:00:00'],\n",
      "              dtype='datetime64[ns]', length=480, freq=None)\n",
      "Number of unique missing timestamps:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#convert datacreationdate to datetime, coercing errors to NaT\n",
    "df_aqi['datacreationdate'] = pd.to_datetime(df_aqi['datacreationdate'], errors='coerce')\n",
    "\n",
    "#create a complete range of hourly timestamps\n",
    "full_time_range = pd.date_range(start=\"2016-11-25 13:00\", end=\"2024-06-30 23:00\", freq='h')\n",
    "\n",
    "#identify missing timestamps by comparing with the datacreationtime column\n",
    "missing_timestamps = full_time_range.difference(df_aqi['datacreationdate'])\n",
    "\n",
    "#display missing timestamps and number of unique missing timestamps\n",
    "print(\"Missing timestamps:\")\n",
    "print(missing_timestamps)\n",
    "\n",
    "print(\"Number of unique missing timestamps:\")\n",
    "display(missing_timestamps.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datacreationdate</th>\n",
       "      <th>aqi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2016-11-28 10:00:00</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2016-11-28 11:00:00</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2016-11-28 12:00:00</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2016-11-28 13:00:00</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2016-11-28 14:00:00</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2016-11-28 15:00:00</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2016-11-28 16:00:00</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2016-11-28 17:00:00</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2016-11-28 18:00:00</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      datacreationdate  aqi\n",
       "69 2016-11-28 10:00:00   52\n",
       "70 2016-11-28 11:00:00   54\n",
       "71 2016-11-28 12:00:00   57\n",
       "72 2016-11-28 13:00:00   77\n",
       "73 2016-11-28 14:00:00   79\n",
       "74 2016-11-28 15:00:00   81\n",
       "75 2016-11-28 16:00:00   82\n",
       "76 2016-11-28 17:00:00   83\n",
       "77 2016-11-28 18:00:00   84"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check if timestamps for missing data are continuous by printing the missing data for a certain period\n",
    "start_date = '2016-11-28 10:00:00'\n",
    "end_date = '2016-11-28 23:00:00'\n",
    "display(df_aqi[(df_aqi['datacreationdate'] >= start_date) & (df_aqi['datacreationdate'] <= end_date)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set datacreationdate as the index and reindex the DataFrame to include all timestamps\n",
    "df_aqi.set_index('datacreationdate', inplace=True)\n",
    "df_aqi = df_aqi.reindex(full_time_range)\n",
    "\n",
    "#copy the DataFrame before interpolation\n",
    "df_aqi_original = df_aqi.copy()\n",
    "\n",
    "#interpolate missing values and round interpolated values to nearest integer\n",
    "df_aqi['aqi'] = df_aqi['aqi'].interpolate(method='time').round()\n",
    "\n",
    "#create the \"interpolated\" column\n",
    "df_aqi['interpolated'] = 0\n",
    "df_aqi.loc[df_aqi_original['aqi'].isna() & df_aqi['aqi'].notna(), 'interpolated'] = 1\n",
    "\n",
    "#reset the index to have datacreationdate as a column again\n",
    "df_aqi.reset_index(inplace=True)\n",
    "df_aqi.rename(columns={'index': 'datacreationdate'}, inplace=True)\n",
    "\n",
    "#display the number of rows with interpolated = 1 \n",
    "df_aqi['interpolated'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename datacreationdate column as time for clarity\n",
    "df_aqi = df_aqi.rename(columns={\"datacreationdate\": \"time\"})\n",
    "\n",
    "#save df_aqi to a CSV file\n",
    "df_aqi.to_csv('df_aqi.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
